{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de35d6a1-3656-4388-b721-89275fd7d497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: document_1.pdf\n",
      "Downloaded: document_2.pdf\n",
      "Downloaded: document_3.pdf\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# List of PDF URLs\n",
    "pdf_urls = [\n",
    "    \"https://www.fia.com/sites/default/files/fia_2026_f1_regulations_-_section_b_sporting_-_iss01_-_2024-10-17.pdf\",\n",
    "    \"https://www.fia.com/sites/default/files/fia_2026_f1_regulations_-_section_c_technical_-_iss09_-_2024-10-17.pdf\",\n",
    "    \"https://www.fia.com/sites/default/files/fia_2026_f1_regulations_-_section_c_technical_-_iss09_-_2024-10-17.pdf\"\n",
    "]\n",
    "\n",
    "# Function to download a PDF from a given URL\n",
    "def download_pdf(url, filename):\n",
    "    try:\n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            with open(filename, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "                print(f\"Downloaded: {filename}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {filename}. Status code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while downloading {filename}: {str(e)}\")\n",
    "\n",
    "# Download each PDF in the list\n",
    "for idx, url in enumerate(pdf_urls):\n",
    "    filename = f\"document_{idx+1}.pdf\"  # Save each PDF with a unique name\n",
    "    download_pdf(url, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c2d3066-d299-4d2a-a013-6b89fc330cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.35.68)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.68 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3) (1.35.68)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3) (0.10.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from botocore<1.36.0,>=1.35.68->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from botocore<1.36.0,>=1.35.68->boto3) (2.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.68->boto3) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e108bc2f-0284-44ea-a5fd-27ecf55bce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded document_1.pdf to S3 bucket f1poc\n",
      "Uploaded document_2.pdf to S3 bucket f1poc\n",
      "Uploaded document_3.pdf to S3 bucket f1poc\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Step 3: Set up boto3 client\n",
    "s3 = boto3.client('s3',\n",
    "                  aws_access_key_id='key',\n",
    "                  aws_secret_access_key='key',\n",
    "                  region_name='us-east-2')\n",
    "\n",
    "bucket_name = \"f1poc\"\n",
    "\n",
    "# Upload PDFs to S3\n",
    "for idx in range(1, 4):  # Assuming you have three PDFs downloaded\n",
    "    pdf_filename = f\"document_{idx}.pdf\"\n",
    "    if os.path.exists(pdf_filename):\n",
    "        s3.upload_file(pdf_filename, bucket_name, pdf_filename)\n",
    "        print(f\"Uploaded {pdf_filename} to S3 bucket {bucket_name}\")\n",
    "    else:\n",
    "        print(f\"File {pdf_filename} not found for upload.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7996e74-a39c-4745-88d1-65e1dfa719e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07200e3f-11fd-4896-bcc3-e0dfa6e16188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Keys (Keep this cell private and do not share your notebook)\n",
    "PINECONE_API_KEY = \"key\"\n",
    "OPENAI_API_KEY = \"key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45469586-f25c-4591-af69-f3851f627bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index f1-regulations created successfully\n",
      "Processed document_1.txt in 8 chunks\n",
      "Processed document_2.txt in 21 chunks\n",
      "Processed document_3.txt in 21 chunks\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Initialize OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def chunk_text(text, max_tokens=8000):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoding.encode(text)\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(tokens), max_tokens):\n",
    "        chunk = encoding.decode(tokens[i:i + max_tokens])\n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Create or get index\n",
    "index_name = \"f1-regulations\"\n",
    "if index_name not in [idx.name for idx in pc.list_indexes()]:\n",
    "    try:\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=1536,  # Dimension for text-embedding-ada-002\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(\n",
    "                cloud='aws',\n",
    "                region='us-east-1'\n",
    "            )\n",
    "        )\n",
    "        print(f\"Index {index_name} created successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create index: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Retrieve index instance\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Process documents\n",
    "for idx in range(1, 4):\n",
    "    text_filename = f\"document_{idx}.txt\"\n",
    "    if os.path.exists(text_filename):\n",
    "        try:\n",
    "            with open(text_filename, 'r') as text_file:\n",
    "                text = text_file.read()\n",
    "            \n",
    "            chunks = chunk_text(text)\n",
    "            \n",
    "            for chunk_idx, chunk in enumerate(chunks):\n",
    "                response = client.embeddings.create(input=chunk, model=\"text-embedding-ada-002\")\n",
    "                embedding = response.data[0].embedding\n",
    "                \n",
    "                # Create a unique ID for each chunk\n",
    "                chunk_id = f\"{text_filename}_chunk_{chunk_idx}\"\n",
    "                \n",
    "                # Upsert the embedding to Pinecone\n",
    "                index.upsert([(chunk_id, embedding, {\"source\": text_filename})])\n",
    "            \n",
    "            print(f\"Processed {text_filename} in {len(chunks)} chunks\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {text_filename}: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"{text_filename} not found\")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
